
挖坑，待填坑：

<a name="TGgR5"></a>
# 1 介绍

影像组学特征筛选主要目的是从大量特征中挑选出对分类、预测或分析任务最有贡献的特征。**为了避免影像组学特征数量过多导致建立的机器学习模型过度拟合，需要对特征进行筛选降维。**

**常见的影像组学特征筛选方法**：

1. 方差分析（Variance Analysis）：基于特征的方差进行筛选，删除方差较小的特征。方差较小的特征在样本间的差异较小，对分类和预测任务的贡献可能较低。
2. 相关性分析（Correlation Analysis）：计算特征之间的相关性，删除高度相关的特征。高度相关的特征可能提供相似的信息，保留一个即可减少冗余。
3. 卡方检验（Chi-squared Test）：用于分类问题的特征筛选，计算特征与类别之间的卡方统计量，选择与类别关系最紧密的特征。
4. 互信息（Mutual Information）：衡量特征与目标变量之间的信息共享程度，选择与目标变量关系较强的特征。
5. 递归特征消除（Recursive Feature Elimination，RFE）：使用模型（如支持向量机、随机森林等）进行特征排序，递归移除较弱的特征，直到达到预定的特征数量。
6. LASSO回归（Least Absolute Shrinkage and Selection Operator）：通过加入L1正则化项的线性回归方法，能够实现特征选择和系数估计。LASSO倾向于产生稀疏解，将不重要特征的系数压缩为零。
7. 主成分分析（Principal Component Analysis，PCA）：一种无监督降维方法，通过将原始特征转换到新的正交坐标系，提取主成分。PCA能够减少特征间的相关性，但可能导致原始特征失去解释性。
8. 最小冗余最大相关（Minimum Redundancy Maximum Relevance，mRMR）：旨在选择与目标变量相关性较高且互相冗余较低的特征子集。
9. 机器学习模型内置的特征重要性：一些机器学习模型（如随机森林、梯度提升树等）可以直接输出特征重要性，用于特征筛选。

影像组学特征筛选方法的选择取决于具体问题和数据类型。在实际应用中，可以尝试多种方法并比较它们的性能，选择适合当前问题的特征筛选方法。


<a name="prwYF"></a>
# 2 方法简要介绍

<a name="kzuXT"></a>
## 2.1 T检验

- 单样本 T 检验：检验样本均值与已知总体均值的差异性，要求样本服从正态分布。
- 配对样本 T 检验：检验配对样本均值是否有显著性差异，要求差值服从正态分布，无方差齐性要求。

例：同一组病人术前、术后某指标分布的差异性检验

- 两独立样本 T 检验：检验非配对样本均值是否有显著性差异，要求两样本均服从正态分布，要求方差齐。

例：某指标在不同性别间的分布差异性检验

**T 检验在 Python 中实现：**<br />正态性检查：K-S 检验 (p > 0.05，则服从正态分布）, 样本量较大时可不做<br />• Python 函数：scipy.stats.kstest(sample, cdf = 'norm')<br />• 函数输出：统计量，p 值<br />方差齐性检验：levene 检验 (p > 0.05，则具有方差齐性）<br />• Python 函数：scipy.stats.levene(sample1, sample2)<br />两独立样本 T 检验 (p < 0.05 具有显著性差异）<br />• Python 函数：scipy.stats.ttest_ind(sample1, sample2, equal_var)<br />• 方差齐 equal_var = Ture，执行 T 检验；否则，equal_var = False，执行 Welch’s 检验<br />不服从正态分布的数据，应使用配对 Wilcoxon 秩和检验



<a name="V3pRQ"></a>
# 2.2 lasso特征筛选
LASSO = Least Absolute Shrinkage and Selection Operator，套索算法<br />Lasso 给简单线性回归加了 L1 正则化，可以将不重要变量的系数收缩到 0 ，从而实现了特征选择。

- 一种嵌入式特征选择方法
- **LASSO 核心原理**：把**不重要**的特征系数**变为 0**

![image.png](https://cdn.nlark.com/yuque/0/2024/png/38497976/1705222033516-d1093df8-8034-4e8a-b20a-8d0f020b530e.png#averageHue=%23f7f7f7&clientId=u03cb9075-1b1a-4&from=paste&height=335&id=u45b8b0af&originHeight=670&originWidth=1917&originalType=binary&ratio=2&rotation=0&showTitle=false&size=246604&status=done&style=none&taskId=u037b8a9b-cd6f-4378-bbce-2b485e4658d&title=&width=958.5)





<a name="ltieQ"></a>
## 2.3 最小冗余最大相关（Minimum Redundancy Maximum Relevance，mRMR）
mRMR（Max-Relevance and Min-Redundancy）。如果选中的特征与目标相关性很好，同时特征间的冗余又非常小，即特征同目标变量依赖高，特征之间差异却很大，那么也有理由认为该特征子集是一个好的选择。mRMR（minimum redundancy maximum relevance，最小冗余最大相关）就是这样的一种特征选择方法。

相关性分析：计算特征与目标变量间的相关性；度量方式可根据数据类型的不同使用互信息/最大信息系数和方差检验等，记为C。 冗余性分析：计算特征间的相关性，度量方式可使用互信息/最大信息系数和相关系数等，记为R。 最后使用Max(C-R)或max(C/R)综合考虑相关性和冗余性。


<a name="T2W99"></a>
## 2.4 PCA主成分分析降维：


<a name="jALcW"></a>
# 3 代码示例：


```python
import numpy as np
import pandas as pd
#from patsy import dmatrix
import os

## 导入数据
# pyradiomics 提取的 1648 维特征，从第 40 列开始
# 原始的clinical表格
origin_data = pd.read_csv('Radiomics-Features.csv')
sample_list = np.loadtxt('dataset.txt', delimiter=None, dtype=str)
#label_origin_data = pd.read_csv('/Users/huahua/PycharmProjects/radiomics_home/local/nsclc_411/data/Lung1.clinical_.csv')
```


```
# 影像组学特征处理及标签
idx = sample_list[:, 0]
label = sample_list[:, 1] 

#因为有些特征是字符串，直接删掉
cols=[x for i,x in enumerate(origin_data.columns) if type(origin_data.iat[1,i]) == str]
#cols.remove('index')
origin_data=origin_data.drop(cols,axis=1)

data = np.array(origin_data)[:,:]  #提取特征数值，从25列开始，376*107;新版特征40列开始，376*1648
pd_data = origin_data.iloc[:,:]


data.shape
```



```
from sklearn.preprocessing import StandardScaler  # 标准化，返回值为标准化后的数据
from sklearn.preprocessing import MinMaxScaler    # 缩放，按列缩放到[0,1]
from sklearn.preprocessing import Normalizer          # 正则化，按行l1／l2范数为固定值

process_data = MinMaxScaler().fit_transform(data)
#process_data = StandardScaler().fit_transform(data)
#print(np.max(process_data,axis=0))
#np.save('lung_feature_1648.npy',process_data)   #保存归一化特征
#np.save('lung_target',label-1)         #保存对应标签376
```



```
from sklearn import preprocessing
from sklearn.feature_selection import VarianceThreshold
varthreshold = 0.015
sel_varthres = VarianceThreshold(threshold=varthreshold)
process_data = sel_varthres.fit_transform(process_data)
print(process_data.shape)


from sklearn.model_selection import train_test_split
from sklearn.model_selection import GridSearchCV
from sklearn.decomposition import PCA
from sklearn.metrics import roc_auc_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
from sklearn.svm import SVC

X_train,X_test,y_train,y_test = train_test_split(process_data, label, test_size = 0.3, random_state=10)

n_components = 150
#pca = PCA(n_components = n_components).fit(X_train)
#X_train_pca,X_test_pca = pca.transform(X_train),pca.transform(X_test)
X_train_pca, X_test_pca = X_train, X_test
```


```
import matplotlib.pyplot as plt

## 用rf拟合训练集，然后对特征重要性排序
from sklearn.ensemble import RandomForestClassifier
clf_rf = RandomForestClassifier(n_estimators = 1000)
clf_rf.fit(X_train, y_train)
print(clf_rf.score(X_test,y_test))
f_importances = clf_rf.feature_importances_
f_names = np.arange(X_train.shape[1])
f_std = np.std([tree.feature_importances_ for tree in clf_rf.estimators_], axis = 0)
zz = zip(f_importances, f_names, f_std)
zzs = sorted(zz, key = lambda x: x[0], reverse = True)

nums = 10
imps = [x[0] for x in zzs[:nums]]
labels = [x[1] for x in zzs[:nums]]
errs = [x[2] for x in zzs[:nums]]
plt.subplots(figsize = (15,5))
plt.bar(range(nums), imps, color = 'r', yerr = errs, align = 'center')
plt.xticks(range(nums),labels, rotation = -90)
```



```
# 用训练好的rf评估特征重要性排序，取前k个用于进一步训练
rf_id = []
k = 100

for i in range(k):
    rf_id.append(zzs[i][1])

data_selected = process_data[:,rf_id]
data_selected.shape
```




```
for i, (name, label) in enumerate(sample_list):
    file = 'radiomics/' + name + '-radiomics'
    np.save(file, data_selected[i, :])
    print(str(i+1) + '/325 | ' + name)
    
print('Done')
```

<a name="GuK4H"></a>
# 参考

【影像组学特征筛选和降维（T检验+LASSO+PCA）】<br />[https://blog.csdn.net/zea408497299/article/details/125307687](https://blog.csdn.net/zea408497299/article/details/125307687)











